\documentclass[12pt]{article}
\usepackage[canadien]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{graphicx}
\graphicspath{ {./logs/figures/} }
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{float}
\usepackage{bm}
\usepackage{url}
\usepackage[dvipsnames]{xcolor}
\usepackage{todonotes}
\usepackage{hyperref}
\usepackage{monpackage}

% If your paper is accepted, change the options for the package
% aistats2e as follows:
%
%\usepackage[accepted]{aistats2e}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.
\setlength{\parindent}{0cm}
\addtolength{\oddsidemargin}{-2cm}
\addtolength{\evensidemargin}{-2cm}
\setlength{\textwidth}{17.78cm}
\addtolength{\topmargin}{-2.25cm}
\setlength{\textheight}{23.24cm}
\addtolength{\parskip}{5mm}
\pagestyle{fancy}

%************
%* COMMANDS *
%************

\input{math_commands}

\newif\ifexercise
\exercisetrue
%\exercisefalse

\newif\ifsolution
\solutiontrue
%\solutionfalse

\usepackage{booktabs}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{exercise}{Question}%[chapter]
\newtheorem{answer}{Answer} % asterisk to remove ordering

\newcommand{\Exercise}[1]{
\ifexercise#1\fi
}

\definecolor{answer}{rgb}{0.00, 0.12, 0.60}
\newcommand{\Answer}[1]{
\ifsolution\color{answer}\begin{answer}#1\end{answer}\fi
}

\newif\ifexercise
\exercisetrue
%\exercisefalse

\newif\ifsolution
\solutiontrue
%\solutionfalse

\usepackage{enumitem}
\newcommand{\staritem}{
\addtocounter{enumi}{1}
\item[$\phantom{x}^{*}$\theenumi]}
\setlist[enumerate,1]{leftmargin=*, label=\arabic*.}

\newcommand{\customcommandlreg}{\ensuremath{L_{\textnormal{reg}}(f(\mathbf{x}^{(i)}, \mathbf{\theta}), \mathbf{y}^{(i)})}}
\newcommand{\customcommandloss}{\ensuremath{L}(f(\mathbf{x}^{(i)}, \mathbf{\theta}), \mathbf{y}^{(i)})}

\def\vdelta{{\bm{\delta}}}
\usetikzlibrary{positioning}

\begin{document}


\fancyhead{}
\fancyfoot{}

\fancyhead[L]{
  \begin{tabular}[b]{l}
    IFT6135-A2023  \\
    Prof: Aishwarya Agrawal \\
  \end{tabular}
}
\fancyhead[R]{
  \begin{tabular}[b]{r}
    Assignment 2, Theoretical Part   \\
    RNN, Optimization, Regularization, Transformers, Normalization\\
  \end{tabular}
}
\fancyfoot[C]{- Do not distribute -}

\vspace{1cm}

\shorthandoff{:}
{\textbf{Due Date: November 14th, 2023 at 11:00 pm}}\\


\vspace{-0.5cm}
\underline{Instructions}%
\renewcommand{\labelitemi}{\textbullet}

\begin{itemize}
\item \emph{For all questions, show your work!}
\item \emph{Use LaTeX and the template we provide when writing your answers.
You may reuse most of the notation shorthands, equations and/or tables.
See the assignment policy on the course website for more details.}
\item \emph{The use of AI tools like Chat-GPT to find answers or parts of answers for any question in this assignment is not allowed. However, you can use these tools to improve the quality of your writing, like fixing grammar or making it more understandable. If you do use these tools, you must clearly explain how you used them and which questions or parts of questions you applied them to. Failing to do so or using these tools to find answers or parts of answers may result in your work being completely rejected, which means you'll receive a score of 0 for the entire theory or practical section.}
\item \emph{Submit your answers electronically via Gradescope.}
\end{itemize}
\subsection*{Problem 2}
\subsubsection*{Problem 2.5}
My modules are all linear and are composed of 4 different
layers:$(W_{k}, W_{v}, W_{q}, W_{o})$ with bias terms. Each of these square matrix is
of size $(numheads \times headsize)^{2}$ and has a bias. Therefore, there are
$$4 \pr{(numheads \times headsize)^{2} + numheads \times headsize}$$

\subsection*{Problem 3}
\subsubsection*{Problem 3.1}

These are the lowest validation perplexity score across epochs:
\begin{enumerate}
  \item gpt1 layer 1 adam minimal validation perplexity: 148.970
  \item gpt1 layer 1 adamw min validation perplexity: 148.512
  \item gpt1 layer 1 momentum min validation perplexity: 684.063
  \item gpt1 layer 1 sgd min validation perplexity: 1502.892
  \item gpt1 layer 2 adamw min validation perplexity: 567.639
  \item gpt1 layer 4 adamw min validation perplexity: 1486.629
  \item lstm layer 1 adam min validation perplexity: 144.289
  \item lstm layer 1 adamw min validation perplexity: 144.154
  \item lstm layer 1 momentum min validation perplexity: 1654.189
  \item lstm layer 1 sgd min validation perplexity: 2173.387
  \item lstm layer 2 adamw min validation perplexity: 139.819
  \item lstm layer 4 adamw min validation perplexity: 160.328
\end{enumerate}

We also have obtained the following figures:

\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_1_adam.png}
     \caption{gpt1 with 1 layer and optimized with adam perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_1_adamw.png}
     \caption{gpt1 with 1 layer and optimized with adamw perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_1_momentum.png}
     \caption{gpt1 with 1 layer and optimized with momentum perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_1_sgd.png}
     \caption{gpt1 with 1 layer and optimized with sgd perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_1_adam.png}
     \caption{lstm with 1 layer and optimized with adam perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_1_adamw.png}
     \caption{lstm with 1 layer and optimized with adamw perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_1_momentum.png}
     \caption{lstm with 1 layer and optimized with momentum perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_1_sgd.png}
     \caption{lstm with 1 layer and optimized with sgd perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_2_adamw.png}
     \caption{gpt1 with 2 layer and optimized with adamw perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{gpt1_layer_4_adamw.png}
     \caption{gpt1 with 4 layer and optimized with adamw perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_2_adamw.png}
     \caption{lstm with 2 layer and optimized with adamw perplexity over time and epochs}
\end{figure}
\begin{figure}[H]
     \centering
     \includegraphics[scale=0.4]{lstm_layer_4_adamw.png}
     \caption{lstm with 4 layer and optimized with adamw perplexity over time and epochs}
\end{figure}

\subsubsection*{Problem 3.2}
Here are the results of the 12 experiments:
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{llllllllll}
Exp & Architecture &  \#layers & Optimizer &Train Loss & Train PPL & Validation Loss & Validation PPL & Test Loss & Test PPL \\ \hline
5  & GPT1 & 1 & Adam      &3.765 & 43.19 & 5.16 & 148.970 & 5.182 & 178.151 \\
6  &\bf{GPT1} & \bf{1}& \bf{Adamw}     &\bf{3.752}&\bf{42.634} &\bf{5.157} & \bf{148.512} & \bf{5.180} & \bf{177.837} \\
8  & GPT1 & 1 & Momentum  &6.583 & 715.571 & 6.528 & 684.063 & 6.504 & 667.813 \\
7  & GPT1 & 1 & SGD       &7.381 & 1605.992 & 7.315 & 1502.892 & 7.291 & 1467.53 \\
11 & GPT1 & 2 & Adamw     &7.347 & 590.611 & 6.341 & 567.639 & 6.315 & 553.009 \\
12 & GPT1 & 4 & Adamw     &7.347 & 1552.593 & 7.304 & 1486.629 & 7.274 & 1443.59\\
1  & LSTM & 1 & Adam      &4.399 & 81.436 & 4.971 & 144.289 & 4.995 & 147.777 \\
2  & LSTM & 1 & Adamw     &4.392 & 80.854 & 4.970 & 144.154 & 5.001 & 148.673 \\
4  & LSTM & 1 & Momentum  &7.446 & 1748.463 & 7.411 & 1654.189 & 7.377 & 1600.139 \\
3  & LSTM & 1 & SGD       &7.750 & 2322.216 & 7.684 & 2173.387 &  7.644 & 2088.849 \\
9  & \bf{LSTM} & \bf{2} & \bf{Adamw}     &\bf{4.0733} & \bf{58.754} & \bf{4.986} & \bf{139.819} & \bf{5.021} & \bf{151.656} \\
10 & LSTM & 4 & Adamw     &4.470 & 87.406 & 5.086 & 160.328 & 5.106 & 165.131 \\
\end{tabular}}
\caption{Results for the 12 experiments. Each models were trained on 10 epochs}
\end{table}

\subsubsection*{Problem 3.3}
If the goal was to minimize the training time of a model, I would choose either
the SGD optimizer or the momentum optimizer with an LSTM. They were the fastest
to train. If the goal was to generalize well, I would chose the LSTM with Adam
or Adamw or GPT1 with Adamw or Adam. These four models had the best test loss for a
single layer model and were all close to each others with respect to the
test loss. Their test perplexity was generally the lowest too.
\subsubsection*{Problem 3.4}
Both SGD and momentum generate high validation perplexity and do not generalize
as well as Adam and Adamw, when comparing the test loss and the test perplexity.
The high precision of Adam and Adamw came at a slightly higher training time.
Therefore, SGD and momentum need more training epochs than Adam and Adamw to
converge.
\subsubsection*{Problem 3.5}
The LSTM performed better for this experiment. It was not yet overfitting, while
the GPT1 model was.  It also had better validation and test perplexity, which
generally mean the model will perform better when encountering new data.
\subsubsection*{Problem 3.6}
The result of the transformer architecture are underwhelming. It generally
performed worst than the LSTM architecture. A possible reason is that the LSTM
layers perform better than the transformer layers when there are only a few
number of layers, while the transformers layers scale better when the depth of
the network increases.
\subsubsection*{Problem 3.7}
All models were trained on a Nvidia GeForce RTX 3060 on my personal computer,
with around 12 gbs of VRAM.

We summarize the use of memory in the following table:
\begin{table}[H]
\begin{tabular}{llllll}
\hline
\multicolumn{1}{|l|}{N} & \multicolumn{1}{l|}{Architecture} & \multicolumn{1}{l|}{Optimizer} & \multicolumn{1}{l|}{\#layers} & \multicolumn{1}{l|}{Average memory used (MiB)} & \multicolumn{1}{l|}{Average utilization (\%)} \\ \hline
5 & GPT1 & Adam & 1 & 4585.33 & 37.32 \\
6 & GPT1 & Adamw & 1 & 4413.33 & 35.91 \\
7 & GPT1 & Momentum & 1 & 4392.22 & 35.74 \\
7 & GPT1 & SGD & 1 & 3762.44 & 30.61 \\
11 & GPT1 & Adamw & 2 & 4308 & 35.05 \\
12 & GPT1 & Adamw & 4 & 5940.22 & 48.34 \\
1 & LSTM & Adam & 1 & 3610.33 & 29.38 \\
2 & LSTM & Adamw & 1 & 3587.0 & 29.19 \\
3 & LSTM & Momentum & 1 & 3610.44 & 29.38 \\
4 & LSTM & SGD & 1 & 2973.55 & 24.11 \\
9 & LSTM & Adamw & 2 & 3507.55 & 28.54 \\
10 & LSTM & Adamw & 4 & 3682.22 & 29.96
\end{tabular}
\caption{Memory usage of different models and optimizers during the 12 experiments}
\end{table}
Each models has the following number of parametrs:
\begin{itemize}
    \item lstm layer 1: 34107392
    \item lstm layer 2: 36208640
    \item lstm layer 4: 40411136
    \item gpt1 layer 1: 38372352
    \item gpt1 layer 2: 45460224
    \item gpt1 layer 4: 59635968
\end{itemize}
As we can see in the table, the GPT1 architecture was more demandant in terms of
memory than the LSTM architecture. We can see how the GPT1 memory usage scales
with the number layers added to the architecture. This is a not a suprising
result, the number of parameters in the GPT1 architecture goes up much faster
than the number of parameters in the LSTM architecture. It is also interesting
to see how the Adam based optimizers increase the memory usage, independently of
the architecture. Finally, we can see how the LSTM architecture scales much
better than the GPT1 in terms of memory used when we increase the number of
layers.
\subsubsection*{Problem 3.8}
GPT1 with one layer and the adamw optimizer showed signs of overfitting: The
validation perplexity started going up after epoch 4, while the training
perplexity kept diminishing.  Both GPT1 architectures with more than one layer
could have higher performance with more training time, especially the 4 layer
model. They were not overfitting yet.  The LSTM architecture with one layer and
the adamw optimizer was not yet overfitting, more trainig epoch could have been
beneficial for it's performance.  The LSTM with 2 layer was not overfitting yet.
Finally, the LSTM with 4 layers was not yet overfitting, it was plateauing. More
training time would not have been beneficial for this model.  Overall, both
classes of models were prone to overfit, but in my experiences the LSTM class
overfit slightly more often and the smaller models were overfitting faster than
the larger ones. To reduce the risks of overfitting, it is important to
regularize the models. It allows the model to be trained for longer while
reducing the likelyhood of overfitting. Another strategy is to apply dropout,
which can prevent the model to rely too heavily on a small and specific set of
weights. Finally, early stopping strategies can be employed to prevent
overfitting.

\end{document}
